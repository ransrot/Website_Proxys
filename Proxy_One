from bs4 import BeautifulSoup
import random
from selenium import webdriver
from selenium.webdriver.firefox.options import Options
from fake_useragent import UserAgent
import argparse
import sys

class Parser:
	def __init__(self):
		self.args = argparse.ArgumentParser()
		self.args.add_argument("--url", help="Select the URL type you want. SOCKS4, SOCKS5, HTTP, HTTPS", type=self.validate_url_type)

		self.args_parsed = self.args.parse_args()

	def return_url_type(self):
		return self.args_parsed.url

	def validate_url_type(self, url_type):
		valid_url = ["HTTP", "HTTPS", "SOCKS5", "SOCKS4"]
		if not url_type in valid_url:
			print("[-] Invalid url")
			exit()
		return url_type


class Proxy:
	def __init__(self, url=None, proxy_type=None, user_agent=False):
		self.proxy_type = proxy_type
		self.user_agent = user_agent
		self.url = url
		self.proxy_value = "network.proxy.socks"
		self.proxy_value_port = "network.proxy.socks_port"

		if self.proxy_type:
			if self.proxy_type == "HTTP":
				self.proxy_value = "network.proxy.http"
				self.proxy_value_port = "network.proxy.http_port"

			elif self.proxy_type == "HTTPS":
				self.proxy_value = "network.proxy.https"
				self.proxy_value_port = "network.proxy.https_port"
			
			else:
				print("[-] Invalid Proxy type exiting.")
				exit()

	def request_url(self):
		count = 0
		element_count = 0
		proxy_list = []
		proxy_dict = {}
		print("[*] Getting Proxies...")

		make_headless = Options()
		make_headless.headless = True
		make_headless.add_argument("--no-sandbox")

		driver = webdriver.Firefox(options=make_headless, executable_path="/usr/local/share/WebDriverManager/gecko/v0.26.0/geckodriver-v0.26.0-linux64/geckodriver")
		driver.set_page_load_timeout(10)
		driver.get(self.url)
		get_len_page = driver.find_elements_by_id("totalpg")[0]
		get_len_page = get_len_page.text
		get_len_page = int(get_len_page)

		while True:
			
			submit_button = driver.find_elements_by_id('btn2')[0]
			element_count += 1
			get_contents = driver.page_source
			soup = BeautifulSoup(get_contents, features='lxml')
			tbody_tag = soup.find("tbody", attrs={"class": "table-hover"})
			rows = tbody_tag.find_all("td")

			if element_count > get_len_page:
				print("[*] End")
				break

			for letters in rows:
				count += 1
				proxy_list.append(letters.text)

				if count == 4:
					proxy_dict[proxy_list[0]] = proxy_list[1:]
					count = 0
					proxy_list.clear()
			driver.execute_script("arguments[0].click();", submit_button)	

		driver.close()
		return proxy_dict

	def get_random_ip(self):
		get_content = self.request_url()
		return get_content, random.choice(list(get_content.keys()))

	def set_proxy_preference(self, proxy_ip, proxy_port):
		print("[*] Opening browser")
		fp = webdriver.FirefoxProfile()

		if self.user_agent:
			print("[*] Changing user agent")
			fake_agent = UserAgent()
			fp.set_preference("general.useragent.override", fake_agent.random)

		fp.set_preference("network.proxy.type", 1)
		fp.set_preference(self.proxy_value, proxy_ip)
		fp.set_preference(self.proxy_value_port, proxy_port)
		fp.update_preferences()
		return webdriver.Firefox(firefox_profile=fp, executable_path="/usr/local/share/WebDriverManager/gecko/v0.26.0/geckodriver-v0.26.0-linux64/geckodriver")

	def random_proxy_browser_open(self):  # defaults to SOCKS proxy
		proxy_dict, proxy_ip = self.get_random_ip()
		print(f"[*] Connected to : {proxy_ip} : {proxy_dict[proxy_ip][2]} : {proxy_dict[proxy_ip][0]}")
		return self.set_proxy_preference(proxy_ip, int(proxy_dict[proxy_ip][0]))

	def user_proxy(self, ip, port):
		port = int(port)
		print(f"[*] Connecting to {ip}: {port}")
		return self.set_proxy_preference(ip, port)

def url_types(url_type):
	return f"https://www.proxy-list.download/{url_type}"

if __name__ == '__main__':
	get_index = None
	try:
		get_index = sys.argv[1]
	except IndexError:
		pass
	
	if get_index:
		url = Parser().return_url_type()
		get_url = url_types(url)

	try:
		Proxy(user_agent=True).user_proxy("108.61.219.140", 1080)
	except KeyboardInterrupt:
		print("[*] Exiting")
		exit()
